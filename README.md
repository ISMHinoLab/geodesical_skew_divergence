# alpha-Geodesical Skew Divergence

Official PyTorch Implementation of "alpha-Geodesical Skew Divergence".

> The asymmetric skew divergence smooths one of the distributions by mixing it, to a degree determined by the parameter $\alpha$, with the other distribution. Such divergence is an approximation of the KL divergence that does not require the target distribution to be absolutely continuous with respect to the source distribution. In this paper, an information geometric generalization of  the skew divergence called the  $\alpha$-geodesical skew divergence is proposed, and its properties are studied.


## Visualizations of the alpha-geodesical skew divergence

![](./assets/gs_divergence.png)

![](./assets/gs_divergence_surface.png)
